import os
import requests
from datasets import load_dataset

# Cáº¥u hÃ¬nh chung
DATA_DIR = "./scientific_data"
os.makedirs(DATA_DIR, exist_ok=True)

print("ğŸš€ Báº®T Äáº¦U Táº¢I Dá»® LIá»†U (Cáº¬P NHáº¬T Má»šI)...")

# 1. Táº£i Tá»« Ä‘iá»ƒn NSW (Cáº­p nháº­t nguá»“n má»›i)
# LÆ°u Ã½: ÄÃ£ chuyá»ƒn link tá»« 'blob' sang 'raw' Ä‘á»ƒ táº£i ná»™i dung file JSON
DICT_URL = "https://raw.githubusercontent.com/AnhHoang0529/vn-nsw-dictionary/main/vi-nsw-dict.json"
dict_path = os.path.join(DATA_DIR, "vi-nsw-dict.json") 

try:
    print("ğŸ“¥ Táº£i NSW Dictionary (Má»›i)...")
    resp = requests.get(DICT_URL)
    with open(dict_path, "wb") as f:
        f.write(resp.content)
    print("   âœ… Xong.")
except Exception as e:
    print(f"âš ï¸ Lá»—i táº£i tá»« Ä‘iá»ƒn: {e}")

# HÃ m táº£i dataset tá»« HuggingFace
def download_hf(repo_id, save_name, subset=None, split='train'):
    print(f"ğŸ“¥ Táº£i {repo_id} -> {save_name}...")
    try:
        # Táº£i vá»
        ds = load_dataset(repo_id, subset, split=split, trust_remote_code=True)
        # LÆ°u tÃªn chuáº©n xÃ¡c (.jsonl)
        ds.to_json(os.path.join(DATA_DIR, save_name), force_ascii=False)
        print(f"   âœ… Xong ({len(ds)} dÃ²ng).")
    except Exception as e:
        print(f"   âŒ Lá»—i: {e}")

# --- DANH SÃCH Táº¢I (ÄÃƒ Cáº¬P NHáº¬T) ---

# 1. ViLexNorm (Chuáº©n hÃ³a)
download_hf("visolex/vilexnorm", "vilexnorm.jsonl")

# 2. VSEC (Lá»—i chÃ­nh táº£)
download_hf("nguyenthanhasia/vsec-vietnamese-spell-correction", "vsec.jsonl")

# 3. ViHSD (Context/Toxic)
download_hf("sonlam1102/vihsd", "vihsd.jsonl")

# 4. VSMEC (Context/Emotion)
download_hf("uit-nlp/vietnamese_students_feedback", "vsmec.jsonl")

# 5. WikiANN NER (TÃªn riÃªng)
# WikiANN cáº§n subset='vi' Ä‘á»ƒ láº¥y tiáº¿ng Viá»‡t
download_hf("wikiann", "wikiann_ner.jsonl", subset="vi", split="train")

# 6. WikiLingua (Dáº¥u cÃ¢u) - Láº¥y máº«u 10k Ä‘á»ƒ prepare xá»­ lÃ½ sau
download_hf("wiki_lingua", "wikilingua.jsonl", subset="vietnamese", split="train[:10000]")

print("\nğŸ‰ ÄÃƒ Táº¢I XONG! Cháº¡y tiáº¿p 'prepare_data_final.py'")