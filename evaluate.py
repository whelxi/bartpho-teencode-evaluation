import pandas as pd
import torch
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
from peft import PeftModel
import evaluate
import os

# ==============================================================================
# C·∫§U H√åNH
# ==============================================================================
BASE_MODEL = "vinai/bartpho-syllable"
# ƒê·ªïi th√†nh ƒë∆∞·ªùng d·∫´n local c·ªßa b·∫°n n·∫øu mu·ªën (vd: "./bartpho-teencode-lora")
# Ho·∫∑c d√πng repo HF n·∫øu b·∫°n ƒë√£ push l√™n
ADAPTER_PATH = "whelxi/bartpho-teencode" 
INPUT_CSV = "test.csv"
OUTPUT_CSV = "evaluation_results.csv"
CHART_FILE = "evaluation_chart.png"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

print(f"‚öôÔ∏è Thi·∫øt b·ªã ƒëang s·ª≠ d·ª•ng: {DEVICE.upper()}")

# ==============================================================================
# 1. LOAD MODEL & METRICS
# ==============================================================================
try:
    print("‚è≥ ƒêang t·∫£i Model v√† Metrics...")
    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)
    base_model = AutoModelForSeq2SeqLM.from_pretrained(
        BASE_MODEL,
        torch_dtype=torch.float16 if DEVICE == "cuda" else torch.float32
    ).to(DEVICE)
    
    # Load Adapter
    model = PeftModel.from_pretrained(base_model, ADAPTER_PATH)
    model.eval()
    
    # Load Metrics
    bleu = evaluate.load("sacrebleu")
    rouge = evaluate.load("rouge")
    print("‚úÖ Load th√†nh c√¥ng!")
except Exception as e:
    print(f"‚ùå L·ªói load model: {e}")
    print("üëâ N·∫øu d√πng model local, h√£y ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n ADAPTER_PATH.")
    exit()

# ==============================================================================
# 2. H√ÄM D·ª∞ ƒêO√ÅN
# ==============================================================================
def predict_batch(texts, batch_size=8):
    results = []
    for i in tqdm(range(0, len(texts), batch_size), desc="ƒêang d·ªãch"):
        batch_texts = texts[i : i + batch_size]
        
        inputs = tokenizer(
            batch_texts, 
            return_tensors="pt", 
            max_length=128, 
            truncation=True, 
            padding="max_length"
        ).to(DEVICE)
        
        with torch.no_grad():
            outputs = model.generate(
                input_ids=inputs["input_ids"],
                attention_mask=inputs["attention_mask"],
                max_length=128,
                num_beams=4,
                early_stopping=True
            )
        
        decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)
        results.extend(decoded)
    return results

# ==============================================================================
# 3. CH·∫†Y TR√äN FILE TEST.CSV
# ==============================================================================
if os.path.exists(INPUT_CSV):
    print(f"üìÇ ƒêang ƒë·ªçc file {INPUT_CSV}...")
    df = pd.read_csv(INPUT_CSV)
    
    # Ki·ªÉm tra c·ªôt
    if 'original' not in df.columns or 'normalized' not in df.columns:
        print("‚ùå File CSV thi·∫øu c·ªôt 'original' ho·∫∑c 'normalized'.")
        exit()
        
    inputs = df['original'].astype(str).tolist()
    references = df['normalized'].astype(str).tolist()
    
    # Ch·∫°y d·ª± ƒëo√°n
    predictions = predict_batch(inputs)
    
    # L∆∞u k·∫øt qu·∫£ v√†o DataFrame
    df['prediction'] = predictions
    df.to_csv(OUTPUT_CSV, index=False, encoding='utf-8-sig')
    print(f"üíæ ƒê√£ l∆∞u k·∫øt qu·∫£ d·ª± ƒëo√°n v√†o: {OUTPUT_CSV}")
    
    # ==========================================================================
    # 4. T√çNH TO√ÅN CH·ªà S·ªê (METRICS)
    # ==========================================================================
    print("üìä ƒêang t√≠nh to√°n metrics...")
    
    # BLEU
    bleu_score = bleu.compute(predictions=predictions, references=references)
    
    # ROUGE
    rouge_score = rouge.compute(predictions=predictions, references=references)
    
    metrics = {
        "BLEU": bleu_score['score'],
        "ROUGE-1": rouge_score['rouge1'] * 100, # Rouge tr·∫£ v·ªÅ 0-1, nh√¢n 100 cho ƒë·∫πp
        "ROUGE-2": rouge_score['rouge2'] * 100,
        "ROUGE-L": rouge_score['rougeL'] * 100
    }
    
    print("\n" + "="*40)
    print("K·∫æT QU·∫¢ ƒê√ÅNH GI√Å MODEL")
    print("="*40)
    for k, v in metrics.items():
        print(f"   - {k}: {v:.2f}")
    print("="*40)

    # ==========================================================================
    # 5. V·∫º BI·ªÇU ƒê·ªí
    # ==========================================================================
    plt.figure(figsize=(10, 6))
    sns.set_theme(style="whitegrid")
    
    # T·∫°o DataFrame cho chart
    chart_df = pd.DataFrame({
        'Metric': list(metrics.keys()), 
        'Score': list(metrics.values())
    })
    
    ax = sns.barplot(x='Metric', y='Score', data=chart_df, palette="viridis")
    
    # Th√™m s·ªë li·ªáu l√™n c·ªôt
    for p in ax.patches:
        ax.annotate(f'{p.get_height():.1f}', 
                    (p.get_x() + p.get_width() / 2., p.get_height()), 
                    ha='center', va='center', 
                    xytext=(0, 9), 
                    textcoords='offset points',
                    fontweight='bold')

    plt.title(f"Model Performance Metrics\n(Model: {ADAPTER_PATH})", fontsize=14)
    plt.ylabel("Score (0-100)")
    plt.ylim(0, 110) # Cho d∆∞ ra m·ªôt ch√∫t ·ªü tr√™n
    plt.tight_layout()
    
    plt.savefig(CHART_FILE)
    print(f"üñºÔ∏è  ƒê√£ l∆∞u bi·ªÉu ƒë·ªì v√†o: {CHART_FILE}")
    print("üéâ Ho√†n t·∫•t!")

else:
    print(f"‚ùå Kh√¥ng t√¨m th·∫•y file {INPUT_CSV}")