import torch
import sys
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
from peft import PeftModel

BASE_MODEL = "vinai/bartpho-syllable"
ADAPTER_PATH = "whelxi/bartpho-teencode" 
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# 1. Load Tokenizer & Model
try:
    print("â³ Äang táº£i Tokenizer vÃ  Base Model (Public)...")
    
    # Bá» tham sá»‘ token=...
    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)
    
    base_model = AutoModelForSeq2SeqLM.from_pretrained(
        BASE_MODEL,
        torch_dtype=torch.float16 if DEVICE == "cuda" else torch.float32
    ).to(DEVICE)

    # 2. Load LoRA Adapter
    print(f"ğŸ”— Äang táº£i Adapter tá»«: {ADAPTER_PATH}...")
    
    # Bá» tham sá»‘ token=...
    model = PeftModel.from_pretrained(base_model, ADAPTER_PATH)
    model.eval()
    print("âœ… ÄÃ£ load model thÃ nh cÃ´ng (Cháº¿ Ä‘á»™ Public)!")

except Exception as e:
    print(f"\nâŒ Lá»–I LOAD MODEL: {e}")
    print("ğŸ‘‰ Kiá»ƒm tra láº¡i:")
    print("   1. HF_TOKEN Ä‘Ã£ Ä‘Ãºng chÆ°a vÃ  cÃ³ quyá»n 'Read' khÃ´ng?")
    print("   2. TÃªn repo 'whelxi/bartpho-teencode' cÃ³ chÃ­nh xÃ¡c khÃ´ng?")
    sys.exit(1)

def normalize_teencode(text):
    inputs = tokenizer(
        text, 
        return_tensors="pt", 
        max_length=128, 
        truncation=True, 
        padding="max_length"
    ).to(DEVICE)
    
    with torch.no_grad():
        outputs = model.generate(
            input_ids=inputs["input_ids"],
            attention_mask=inputs["attention_mask"],
            max_length=128,
            num_beams=4,
            early_stopping=True,
            length_penalty=1.0
        )
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

# --- GIAO DIá»†N CHAT TRONG TERMINAL ---
if __name__ == "__main__":
    print("\n" + "="*60)
    print("â˜ï¸   TEST MODEL Tá»ª HUGGING FACE CLOUD  â˜ï¸")
    print("="*60)
    print("ğŸ‘‰ HÆ°á»›ng dáº«n: Nháº­p cÃ¢u teencode rá»“i Enter.")
    print("ğŸ‘‰ GÃµ 'exit', 'quit' hoáº·c 'q' Ä‘á»ƒ thoÃ¡t.")
    print("-" * 60)

    while True:
        try:
            user_input = input("\nğŸ“ Teencode: ").strip()

            if user_input.lower() in ['exit', 'quit', 'q']:
                print("ğŸ‘‹ Táº¡m biá»‡t!")
                break
            
            if not user_input:
                continue

            print("â˜ï¸  Äang gá»i model...", end='\r') 
            
            result = normalize_teencode(user_input)
            
            print(" " * 20, end='\r') 
            print(f"âœ¨ Tiáº¿ng Viá»‡t: {result}")

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ÄÃ£ dá»«ng chÆ°Æ¡ng trÃ¬nh.")
            break
        except Exception as e:
            print(f"âŒ Lá»—i xá»­ lÃ½: {e}")